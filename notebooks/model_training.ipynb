{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Model Training  \n",
    "### 2.1 Import Data and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modeling \n",
    "from sklearn.metrics import accuracy_score\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Support Vector Machine\n",
    "from sklearn import svm\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/training_2009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>sid_type</th>\n",
       "      <th>first_coop_code</th>\n",
       "      <th>first_dist_code</th>\n",
       "      <th>first_hs_code</th>\n",
       "      <th>first_dist_name</th>\n",
       "      <th>first_hs_name</th>\n",
       "      <th>first_hs_alt</th>\n",
       "      <th>first_hs_urbanicity</th>\n",
       "      <th>chrt_ninth</th>\n",
       "      <th>...</th>\n",
       "      <th>ihe_retention_lt_4_yr_part_time</th>\n",
       "      <th>ihe_federal_loan_rate</th>\n",
       "      <th>ihe_share_25_older</th>\n",
       "      <th>ihe_med_debt_completers_all</th>\n",
       "      <th>ihe_med_debt_completers_pmts</th>\n",
       "      <th>ihe_ihe_repay_3_yr_all</th>\n",
       "      <th>ihe_rate_4_yr</th>\n",
       "      <th>ihe_rate_lt_4_yr</th>\n",
       "      <th>ihe_med_earn_10_yrs_after</th>\n",
       "      <th>ihe_pct_earn_gt_25k_6_yrs_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Fake record</td>\n",
       "      <td>WKEC</td>\n",
       "      <td>415</td>\n",
       "      <td>5194</td>\n",
       "      <td>Everett</td>\n",
       "      <td>Everett</td>\n",
       "      <td>0</td>\n",
       "      <td>Town: Remote</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Fake record</td>\n",
       "      <td>GRREC</td>\n",
       "      <td>199</td>\n",
       "      <td>1648</td>\n",
       "      <td>Kingfisher</td>\n",
       "      <td>Kingfisher</td>\n",
       "      <td>0</td>\n",
       "      <td>Town: Distant</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Fake record</td>\n",
       "      <td>GRREC</td>\n",
       "      <td>142</td>\n",
       "      <td>1564</td>\n",
       "      <td>Diamond Lake</td>\n",
       "      <td>Diamond Lake</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural: Distant</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Fake record</td>\n",
       "      <td>OVEC</td>\n",
       "      <td>238</td>\n",
       "      <td>2230</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Pike</td>\n",
       "      <td>0</td>\n",
       "      <td>Suburb: Large</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Fake record</td>\n",
       "      <td>NKCES</td>\n",
       "      <td>517</td>\n",
       "      <td>7658</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Kent</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural: Fringe</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5491</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>24458.5</td>\n",
       "      <td>271.53949</td>\n",
       "      <td>0.757102</td>\n",
       "      <td>0.37589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36100.0</td>\n",
       "      <td>0.591997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid     sid_type first_coop_code  first_dist_code  first_hs_code  \\\n",
       "0    2  Fake record            WKEC              415           5194   \n",
       "1    5  Fake record           GRREC              199           1648   \n",
       "2   12  Fake record           GRREC              142           1564   \n",
       "3   13  Fake record            OVEC              238           2230   \n",
       "4   14  Fake record           NKCES              517           7658   \n",
       "\n",
       "  first_dist_name first_hs_name  first_hs_alt first_hs_urbanicity  chrt_ninth  \\\n",
       "0         Everett       Everett             0        Town: Remote        2009   \n",
       "1      Kingfisher    Kingfisher             0       Town: Distant        2009   \n",
       "2    Diamond Lake  Diamond Lake             0      Rural: Distant        2009   \n",
       "3          Orange          Pike             0       Suburb: Large        2009   \n",
       "4          Foster          Kent             0       Rural: Fringe        2009   \n",
       "\n",
       "   ...  ihe_retention_lt_4_yr_part_time ihe_federal_loan_rate  \\\n",
       "0  ...                              NaN                   NaN   \n",
       "1  ...                              NaN                   NaN   \n",
       "2  ...                              NaN                   NaN   \n",
       "3  ...                              NaN                   NaN   \n",
       "4  ...                              NaN                0.5491   \n",
       "\n",
       "   ihe_share_25_older  ihe_med_debt_completers_all  \\\n",
       "0                 NaN                          NaN   \n",
       "1                 NaN                          NaN   \n",
       "2                 NaN                          NaN   \n",
       "3                 NaN                          NaN   \n",
       "4              0.2428                      24458.5   \n",
       "\n",
       "   ihe_med_debt_completers_pmts  ihe_ihe_repay_3_yr_all  ihe_rate_4_yr  \\\n",
       "0                           NaN                     NaN            NaN   \n",
       "1                           NaN                     NaN            NaN   \n",
       "2                           NaN                     NaN            NaN   \n",
       "3                           NaN                     NaN            NaN   \n",
       "4                     271.53949                0.757102        0.37589   \n",
       "\n",
       "   ihe_rate_lt_4_yr  ihe_med_earn_10_yrs_after  \\\n",
       "0               NaN                        NaN   \n",
       "1               NaN                        NaN   \n",
       "2               NaN                        NaN   \n",
       "3               NaN                        NaN   \n",
       "4               NaN                    36100.0   \n",
       "\n",
       "   ihe_pct_earn_gt_25k_6_yrs_after  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                         0.591997  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52942 entries, 0 to 52941\n",
      "Data columns (total 68 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   sid                              52942 non-null  int64  \n",
      " 1   sid_type                         52942 non-null  object \n",
      " 2   first_coop_code                  52942 non-null  object \n",
      " 3   first_dist_code                  52942 non-null  int64  \n",
      " 4   first_hs_code                    52942 non-null  int64  \n",
      " 5   first_dist_name                  52942 non-null  object \n",
      " 6   first_hs_name                    52942 non-null  object \n",
      " 7   first_hs_alt                     52942 non-null  int64  \n",
      " 8   first_hs_urbanicity              52484 non-null  object \n",
      " 9   chrt_ninth                       52942 non-null  int64  \n",
      " 10  male                             52931 non-null  float64\n",
      " 11  race_ethnicity                   52257 non-null  object \n",
      " 12  frpl                             52258 non-null  float64\n",
      " 13  iep                              52942 non-null  int64  \n",
      " 14  ell                              52942 non-null  int64  \n",
      " 15  gifted                           52942 non-null  int64  \n",
      " 16  ever_alternative                 52942 non-null  int64  \n",
      " 17  scale_score_6_math               0 non-null      float64\n",
      " 18  scale_score_6_read               0 non-null      float64\n",
      " 19  math_ss                          43953 non-null  float64\n",
      " 20  read_ss                          43967 non-null  float64\n",
      " 21  pct_days_absent                  52855 non-null  float64\n",
      " 22  pct_excused_11                   52850 non-null  float64\n",
      " 23  gpa                              51720 non-null  float64\n",
      " 24  scale_score_11_eng               43049 non-null  float64\n",
      " 25  scale_score_11_math              43042 non-null  float64\n",
      " 26  scale_score_11_read              43022 non-null  float64\n",
      " 27  scale_score_11_comp              43012 non-null  float64\n",
      " 28  collegeready_ever_in_hs          52942 non-null  int64  \n",
      " 29  careerready_ever_in_hs           52942 non-null  int64  \n",
      " 30  ap_ever_take_class               52942 non-null  int64  \n",
      " 31  last_acadyr_observed             52942 non-null  int64  \n",
      " 32  transferout                      52942 non-null  int64  \n",
      " 33  dropout                          52942 non-null  int64  \n",
      " 34  still_enrolled                   52942 non-null  int64  \n",
      " 35  ontime_grad                      52942 non-null  int64  \n",
      " 36  chrt_grad                        42975 non-null  float64\n",
      " 37  hs_diploma                       52942 non-null  int64  \n",
      " 38  enroll_yr1_any                   52942 non-null  int64  \n",
      " 39  enroll_yr1_2yr                   52942 non-null  int64  \n",
      " 40  enroll_yr1_4yr                   52942 non-null  int64  \n",
      " 41  enroll_yr2_any                   42975 non-null  float64\n",
      " 42  ihe_code_yr1                     22490 non-null  float64\n",
      " 43  ihe_name_yr1                     22490 non-null  object \n",
      " 44  ihe_barrons_rank_2013            13279 non-null  object \n",
      " 45  ihe_degrees_awarded_predominant  21149 non-null  object \n",
      " 46  ihe_degrees_awarded_highest      21149 non-null  object \n",
      " 47  ihe_act_25th_pctl_cumulative     13056 non-null  float64\n",
      " 48  ihe_act_75th_pctl_cumulative     13056 non-null  float64\n",
      " 49  ihe_act_midpoint_cumulative      13056 non-null  float64\n",
      " 50  ihe_ihe_size                     21149 non-null  float64\n",
      " 51  ihe_part_time_share              21149 non-null  float64\n",
      " 52  ihe_avg_net_price_pub            18200 non-null  float64\n",
      " 53  ihe_avg_net_price_priv           2949 non-null   float64\n",
      " 54  ihe_pell_grant_rate              21149 non-null  float64\n",
      " 55  ihe_retention_4_yr_full_time     13505 non-null  float64\n",
      " 56  ihe_retention_lt_4_yr_full_time  7509 non-null   float64\n",
      " 57  ihe_retention_4_yr_part_time     12188 non-null  float64\n",
      " 58  ihe_retention_lt_4_yr_part_time  7411 non-null   float64\n",
      " 59  ihe_federal_loan_rate            21149 non-null  float64\n",
      " 60  ihe_share_25_older               21149 non-null  float64\n",
      " 61  ihe_med_debt_completers_all      20983 non-null  float64\n",
      " 62  ihe_med_debt_completers_pmts     20983 non-null  float64\n",
      " 63  ihe_ihe_repay_3_yr_all           21149 non-null  float64\n",
      " 64  ihe_rate_4_yr                    13640 non-null  float64\n",
      " 65  ihe_rate_lt_4_yr                 7509 non-null   float64\n",
      " 66  ihe_med_earn_10_yrs_after        21149 non-null  float64\n",
      " 67  ihe_pct_earn_gt_25k_6_yrs_after  21149 non-null  float64\n",
      "dtypes: float64(37), int64(21), object(10)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Select variables of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[['male', 'race_ethnicity', 'frpl','iep', 'ell', 'ever_alternative', 'ap_ever_take_class',\n",
    "           'math_ss', 'read_ss','pct_days_absent', 'gpa', 'scale_score_11_eng', 'scale_score_11_math', \n",
    "           'scale_score_11_read', 'scale_score_11_comp','hs_diploma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0       count\n",
      "hs_diploma       \n",
      "0            9975\n",
      "1           42967\n"
     ]
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(index=temp['hs_diploma'], columns='count')\n",
    "\n",
    "# Display the crosstab\n",
    "print(cross_tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Update int to boolean for demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.loc[df['s_male'] == 0, 's_male'] = 'female'\n",
    "#temp.loc[df['s_male'] == 1, 's_male'] = 'male'\n",
    "#temp.loc[df['s_ell'] == 0, 's_ell'] = 'not_ell'\n",
    "#temp.loc[df['s_ell'] == 1, 's_ell'] = 'ell'\n",
    "#temp.loc[df['s_iep'] == 0, 's_iep'] = 'no_iep'\n",
    "#temp.loc[df['s_iep'] == 1, 's_iep'] = 'iep'\n",
    "#temp.loc[df['sch_charter'] == 0, 'sch_charter'] = 'no_charter'\n",
    "#temp.loc[df['sch_charter'] == 1, 'sch_charter'] = 'yes_charter'\n",
    "#temp.loc[df['sch_alternative'] == 0, 'sch_alternative'] = 'no_alt'\n",
    "#temp.loc[df['sch_alternative'] == 1, 'sch_alternative'] = 'yes_alt'\n",
    "#temp.loc[df['sch_vocational'] == 0, 'sch_vocational'] = 'no_voc'\n",
    "#temp.loc[df['sch_vocational'] == 1, 'sch_vocational'] = 'yes_voc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52942 entries, 0 to 52941\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   male                 52931 non-null  float64\n",
      " 1   race_ethnicity       52257 non-null  object \n",
      " 2   frpl                 52258 non-null  float64\n",
      " 3   iep                  52942 non-null  int64  \n",
      " 4   ell                  52942 non-null  int64  \n",
      " 5   ever_alternative     52942 non-null  int64  \n",
      " 6   ap_ever_take_class   52942 non-null  int64  \n",
      " 7   math_ss              43953 non-null  float64\n",
      " 8   read_ss              43967 non-null  float64\n",
      " 9   pct_days_absent      52855 non-null  float64\n",
      " 10  gpa                  51720 non-null  float64\n",
      " 11  scale_score_11_eng   43049 non-null  float64\n",
      " 12  scale_score_11_math  43042 non-null  float64\n",
      " 13  scale_score_11_read  43022 non-null  float64\n",
      " 14  scale_score_11_comp  43012 non-null  float64\n",
      " 15  hs_diploma           52942 non-null  int64  \n",
      "dtypes: float64(10), int64(5), object(1)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "temp.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male                       2\n",
      "race_ethnicity             5\n",
      "frpl                       2\n",
      "iep                        2\n",
      "ell                        2\n",
      "ever_alternative           2\n",
      "ap_ever_take_class         2\n",
      "math_ss                   83\n",
      "read_ss                   82\n",
      "pct_days_absent        32213\n",
      "gpa                    18739\n",
      "scale_score_11_eng        34\n",
      "scale_score_11_math       31\n",
      "scale_score_11_read       35\n",
      "scale_score_11_comp       29\n",
      "hs_diploma                 2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "vars = temp.columns\n",
    "unique_values_counts = temp.nunique()\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    unique = temp[var].unique()\n",
    "    print(var, unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = temp.drop(columns = ['hs_diploma'], axis = 1)\n",
    "y = temp['hs_diploma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diploma_cnts = y.value_counts()\n",
    "diploma_cnts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show pie chart\n",
    "y.value_counts().plot.pie(autopct = '%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(y.value_counts(), autopct = '%.2f', labels = diploma_cnts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot.pie(autopct = '%2.f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numeric_features = X.select_dtypes(exclude = 'object').columns\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "           (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X.select_dtypes(include='object').columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"object\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Base\n",
    "models['Baseline'] = 0\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "\n",
    "# xgbppst\n",
    "import xgboost as xgb\n",
    "models['xgBoost'] = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "\n",
    "    if models[key] == 0:\n",
    "        ##baseline\n",
    "        predictions = np.ones(len(y_test))\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)\n",
    "    elif models[key] != 0:\n",
    "        # Fit the classifier\n",
    "        models[key].fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        predictions = models[key].predict(X_test)\n",
    "        # Calculate metrics\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_model.plot.barh()\n",
    "ax.legend(\n",
    "    ncol=len(models.keys()), \n",
    "    bbox_to_anchor=(0, 1), \n",
    "    loc='lower left', \n",
    "    prop={'size': 14}\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=1) # numerical\n",
    "#rus = RandomUnderSampler(sampling_strategy='not minority') # string\n",
    "\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y_train_rus.value_counts().plot.pie(autopct = '%.2f')\n",
    "_ = ax.set_title(\"Under-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "\n",
    "    if models[key] == 0:\n",
    "        ##baseline\n",
    "        predictions = np.ones(len(y_test))\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)\n",
    "    elif models[key] != 0:\n",
    "        # Fit the classifier\n",
    "        models[key].fit(X_train_rus, y_train_rus)\n",
    "        # Make predictions\n",
    "        predictions = models[key].predict(X_test)\n",
    "        # Calculate metrics\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_model.plot.barh()\n",
    "ax.legend(\n",
    "    ncol=len(models.keys()), \n",
    "    bbox_to_anchor=(0, 1), \n",
    "    loc='lower left', \n",
    "    prop={'size': 14}\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=1) # numerical\n",
    "#rus = RandomOverSampler(sampling_strategy='not minority') # string\n",
    "\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y_train_ros.value_counts().plot.pie(autopct = '%.2f')\n",
    "_ = ax.set_title(\"Over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "\n",
    "    if models[key] == 0:\n",
    "        ##baseline\n",
    "        predictions = np.ones(len(y_test))\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)\n",
    "    elif models[key] != 0:\n",
    "        # Fit the classifier\n",
    "        models[key].fit(X_train_ros, y_train_ros)\n",
    "        # Make predictions\n",
    "        predictions = models[key].predict(X_test)\n",
    "        # Calculate metrics\n",
    "        accuracy[key] = accuracy_score(predictions, y_test)\n",
    "        precision[key] = precision_score(predictions, y_test)\n",
    "        recall[key] = recall_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_model.plot.barh()\n",
    "ax.legend(\n",
    "    ncol=len(models.keys()), \n",
    "    bbox_to_anchor=(0, 1), \n",
    "    loc='lower left', \n",
    "    prop={'size': 14}\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# define data_dmatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space={'verbosity':0,\n",
    "        'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier:\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(verbosity = space['verbosity'],\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"error\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diploma_cnts = y.value_counts()\n",
    "diploma_cnts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "params = {\"objective\":\"binary:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.3,\n",
    "                'max_depth': 6, 'alpha': 10}\n",
    "\n",
    "xgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"error\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(xgb_clf.feature_importances_, preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.sort_values(0).plot(kind='barh', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
